<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ml/optimization/speed_vit_in_tvm" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">ViT-int8 on TVM：提速4.6倍，比TRT快1.5倍 | 萝卜菜在种树</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ccw1996.github.io/docs/ml/optimization/speed_vit_in_tvm"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ViT-int8 on TVM：提速4.6倍，比TRT快1.5倍 | 萝卜菜在种树"><meta data-rh="true" name="description" content="- 量化节点标注的 pass，告诉 relay 一些算子需要量化，并根据算子功能插入模拟量化节点，模拟量化节点模拟了由浮点数映射到定点数的误差"><meta data-rh="true" property="og:description" content="- 量化节点标注的 pass，告诉 relay 一些算子需要量化，并根据算子功能插入模拟量化节点，模拟量化节点模拟了由浮点数映射到定点数的误差"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://ccw1996.github.io/docs/ml/optimization/speed_vit_in_tvm"><link data-rh="true" rel="alternate" href="https://ccw1996.github.io/docs/ml/optimization/speed_vit_in_tvm" hreflang="en"><link data-rh="true" rel="alternate" href="https://ccw1996.github.io/docs/ml/optimization/speed_vit_in_tvm" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://FUU659621Z-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="萝卜菜在种树 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="萝卜菜在种树 Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="萝卜菜在种树" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.7b761649.css">
<script src="/assets/js/runtime~main.4fbbde6f.js" defer="defer"></script>
<script src="/assets/js/main.6f2e687a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/LLM">LLM</a><button aria-label="Expand sidebar category &#x27;LLM&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/cpp">cpp</a><button aria-label="Expand sidebar category &#x27;cpp&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/cuda">cuda</a><button aria-label="Expand sidebar category &#x27;cuda&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/design_model">design_model</a><button aria-label="Expand sidebar category &#x27;design_model&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/ml">ml</a><button aria-label="Collapse sidebar category &#x27;ml&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/yolo_postprocess">yolo后处理</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/sparse_tensorrt">稀疏矩阵高性能部署</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/attention_is_all_you_need">transformer 解读</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/cache">CPU Cache的测量方法</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/ml/compiler/triton/lower">compiler</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/conv">pytorch卷积层基础七问</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/debug_python">python gdb</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/distribute">pytorch 分布式通信原语</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/flash_attention">FlashAttention 原理</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/ml/framework">framework</a><button aria-label="Expand sidebar category &#x27;framework&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/interview">算法工程师面经</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/onnx">onnx操作</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/ml/openai_triton">openai_triton</a><button aria-label="Expand sidebar category &#x27;openai_triton&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/ml/optimization">optimization</a><button aria-label="Collapse sidebar category &#x27;optimization&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/gemm_GPU">GEMM_GPU</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/SD模型优化">AudioLDM 2，加速</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/custom_onnx_op">onnx 自定义op并导出</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/im2col">再次理解 im2col</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/onnx_modify">onnx 模型修改</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/reduce优化">reduce优化思路</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/sam">硬核详解Segment Anything Model (SAM) TensorRT模型转换</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/script_calc_flops">计算模型需要的算力</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/ml/optimization/speed_vit_in_tvm">ViT-int8 on TVM：提速4.6倍，比TRT快1.5倍</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/optimization/transformer">自动驾驶中基于Transformer的模型和硬件加速分析</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/ml/paper">paper</a><button aria-label="Expand sidebar category &#x27;paper&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/polygraphy">Polygraphy逐层对比onnx和tensorrt模型的输出</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/ml/quantize">quantize</a><button aria-label="Expand sidebar category &#x27;quantize&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/size">卷积神经网络(CNN)张量(图像)的尺寸和参数计算</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/torch-optimize">TORCH.JIT.OPTIMIZE_FOR_INFERENCE</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/ml/training">training</a><button aria-label="Expand sidebar category &#x27;training&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ml/transformer-math">Transformer模型的基础演算</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/other">other</a><button aria-label="Expand sidebar category &#x27;other&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/python">python</a><button aria-label="Expand sidebar category &#x27;python&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/stable_diffusion">stable_diffusion</a><button aria-label="Expand sidebar category &#x27;stable_diffusion&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/time">time</a><button aria-label="Expand sidebar category &#x27;time&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/triton">triton</a><button aria-label="Expand sidebar category &#x27;triton&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/ml"><span itemprop="name">ml</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/ml/optimization"><span itemprop="name">optimization</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ViT-int8 on TVM：提速4.6倍，比TRT快1.5倍</span><meta itemprop="position" content="3"></li></ul></nav><div class="theme-doc-markdown markdown"><h1>STEP 1：QuantizeAnnotate</h1>
<ul>
<li>量化节点标注的 pass，告诉 relay 一些算子需要量化，并根据算子功能插入模拟量化节点，模拟量化节点模拟了由浮点数映射到定点数的误差</li>
<li>相关文件：python/tvm/relay/quantize/_annotate.py</li>
<li>这里我们增加 batch_matmul 的 rewrite 函数：</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@register_annotate_function(&quot;nn.batch_matmul&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def batch_matmul_rewrite(ref_call, new_args, ctx):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Rewrite function for batch_matmul&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if quantize_context().check_to_skip(ref_call):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    lhs_expr, lhs_kind = _get_expr_kind(new_args[0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rhs_expr, rhs_kind = _get_expr_kind(new_args[1])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if lhs_kind is None or lhs_kind == QAnnotateKind.ACTIVATION:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if _analysis.check_constant(lhs_expr):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            lhs_expr = attach_simulated_quantize(lhs_expr, QAnnotateKind.WEIGHT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            lhs_expr = attach_simulated_quantize(lhs_expr, QAnnotateKind.INPUT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if rhs_kind is None or rhs_kind == QAnnotateKind.ACTIVATION:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if _analysis.check_constant(rhs_expr):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            rhs_expr = attach_simulated_quantize(rhs_expr, QAnnotateKind.WEIGHT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            rhs_expr = attach_simulated_quantize(rhs_expr, QAnnotateKind.INPUT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    expr = _forward_op(ref_call, [lhs_expr, rhs_expr])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return QAnnotateExpr(expr, QAnnotateKind.ACTIVATION)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>STEP 2：QuantizeCalibrate</h1>
<ul>
<li>量化校准的 pass，调整量化的阈值和缩放比，避免模型量化后精度下降</li>
<li>相关文件：python/tvm/relay/quantize/_calibrate.py</li>
<li>由于 tvm 仅有 kl 散度校准算法，且其在 ViT 模型量化时表现不佳，因此我们增加了一个简单的 percentile 校准方法，以挽救 ViT 模型精度：</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def _find_scale_by_percentile(arr, percentile=0.99999):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert isinstance(arr, np.ndarray)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x = np.abs(arr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_k = int(x.size * percentile)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return np.partition(x, max_k)[max_k]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def _percentile_scale(mod, dataset):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg = quantize.current_qconfig()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    chunk_by = cfg.calibrate_chunk_by</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    scales = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for samples in collect_stats(mod, dataset, chunk_by):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        logging.info(&quot;finding threshold with percentile for calibration...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        with mp.Pool() as pool:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            scales += list(pool.map(_find_scale_by_percentile, samples))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def func(_):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        scale = scales[func.scale_idx]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        func.scale_idx += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return scale</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    func.scale_idx = 0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>STEP 3：QuantizeRealize</h1>
<ul>
<li>量化实现的 pass，将 fp32 计算图转换为真实的低比特定点数的计算图</li>
<li>相关文件：src/relay/quantize/realize.cc</li>
<li>这里我们增加对 batch_matmul 支持的 Realize 函数：</li>
</ul>
<div class="language-cpp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-cpp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Expr </span><span class="token function" style="color:#d73a49">BatchMatmulRealize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> Call</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> ref_call</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> Array</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">Expr</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> new_args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> ObjectRef</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> ctx</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> QConfig</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> cfg </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token class-name">QConfig</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token function" style="color:#d73a49">Current</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token function" style="color:#d73a49">ICHECK_EQ</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">new_args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">!</span><span class="token plain">new_args</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token generic-function function" style="color:#d73a49">IsInstance</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">TempExprNode</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">||</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">!</span><span class="token plain">new_args</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token generic-function function" style="color:#d73a49">IsInstance</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">TempExprNode</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Expr</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">nullptr</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">auto</span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> lhs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> new_args</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token generic-function function" style="color:#d73a49">as</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">QRealizeIntExprNode</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">auto</span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> rhs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> new_args</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token generic-function function" style="color:#d73a49">as</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">QRealizeIntExprNode</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Expr ldata </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> lhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Expr rdata </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> rhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  DataType dtype </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cfg</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dtype_input</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">lhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dtype </span><span class="token operator" style="color:#393A34">!=</span><span class="token plain"> dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ldata </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Cast</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ldata</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">rhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dtype </span><span class="token operator" style="color:#393A34">!=</span><span class="token plain"> dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rdata </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Cast</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">rdata</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">auto</span><span class="token plain"> ref_attrs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ref_call</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">attrs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token generic-function function" style="color:#d73a49">as</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">BatchMatmulAttrs</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">auto</span><span class="token plain"> attrs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token generic-function function" style="color:#d73a49">make_object</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">BatchMatmulAttrs</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">attrs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">ref_attrs</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  DataType out_dtype </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cfg</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dtype_activation</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  attrs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">out_dtype </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> out_dtype</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Expr ret </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Call</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ref_call</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">op</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">ldata</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> rdata</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Attrs</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">attrs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> ref_call</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">type_args</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Expr mul </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Multiply</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">lhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dom_scale</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> rhs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">dom_scale</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Expr dom_scale </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">FoldConstantOpt</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">mul</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">QRealizeIntExpr</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ret</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dom_scale</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> out_dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">RELAY_REGISTER_OP</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;nn.batch_matmul&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token generic-function function" style="color:#d73a49">set_attr</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">FForwardRewrite</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;FQRealizeRewrite&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> BatchMatmulRealize</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>由于 batch_matmul 的 int8 计算涉及到 out_dtype，因此同时需要更改 include/tvm/relay/attrs/nn.h 中的 BatchMatmulAttrs 和 src/relay/op/nn/nn.c 中的 MakeBatchMatmul 的定义：</p>
<div class="language-cpp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-cpp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">/*! \brief Attributes for batch matmul operator */</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">BatchMatmulAttrs</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token base-clause keyword" style="color:#00009f">public</span><span class="token base-clause"> tvm</span><span class="token base-clause double-colon punctuation" style="color:#393A34">::</span><span class="token base-clause class-name">AttrsNode</span><span class="token base-clause operator" style="color:#393A34">&lt;</span><span class="token base-clause class-name">BatchMatmulAttrs</span><span class="token base-clause operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tvm</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token plain">String auto_scheduler_rewritten_layout</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// The layout after auto-scheduler&#x27;s layout rewrite</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  DataType out_dtype</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token function" style="color:#d73a49">TVM_DECLARE_ATTRS</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BatchMatmulAttrs</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;relay.attrs.BatchMatmulAttrs&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// use 0 bits to indicate none.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">TVM_ATTR_FIELD</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">out_dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">set_default</span><span class="token punctuation" style="color:#393A34">(</span><span class="token generic-function function" style="color:#d73a49">NullValue</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">DataType</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">describe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Output data type, set to explicit type under mixed precision setting&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// Positional relay function to create batch_matmul operator used by frontend FFI.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Expr </span><span class="token function" style="color:#d73a49">MakeBatchMatmul</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Expr x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Expr y</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> DataType out_dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">auto</span><span class="token plain"> attrs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token generic-function function" style="color:#d73a49">make_object</span><span class="token generic-function generic class-name operator" style="color:#393A34">&lt;</span><span class="token generic-function generic class-name">BatchMatmulAttrs</span><span class="token generic-function generic class-name operator" style="color:#393A34">&gt;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  attrs</span><span class="token operator" style="color:#393A34">-&gt;</span><span class="token plain">out_dtype </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> out_dtype</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">static</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> Op</span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain"> op </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token class-name">Op</span><span class="token double-colon punctuation" style="color:#393A34">::</span><span class="token function" style="color:#d73a49">Get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;nn.batch_matmul&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Call</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">op</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">Attrs</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">attrs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>STEP 4：topi-compute &amp; topi-schedule</h1>
<ul>
<li>通过以上三个步骤，tvm 的 relay 图中的 batch_matmul_fp32 计算可以量化变成 batch_matmul_int8 计算，接下来需要实现 int8 算子的 compute 和 schedule</li>
<li>compute：用来描述算子的 tensor 计算过程</li>
<li>schedule：基于特定平台对于算子的计算进行调度，通过 tile，split，reorder，memory_cache 等操作，从而达到更快的运行效率</li>
<li>topi 全称为 tvm operator inventory，是 tvm 为多种平台提供的多种算子的计算和调度实现，我们这里将 batch_matmul_int8 的计算和调度实现注册进 topi 之中</li>
<li>相关文件：python/tvm/topi/cuda/batch_matmul.py</li>
<li>在具体实现中，我们仅考虑 batch_matmul_int8 的 cuda 平台，并使用 dp4a 指令实现 int8 计算调度：</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@autotvm.register_topi_compute(&quot;batch_matmul_int8.cuda&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def batch_matmul_int8(cfg, x, y, out_shape=None, out_dtype=None):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Batch Matmul operator for int8 on CUDA&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if out_dtype is None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out_dtype = x.dtype</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x_shape = get_const_tuple(x.shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    y_shape = get_const_tuple(y.shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert len(x_shape) == 3 and len(y_shape) == 3, &quot;only support 3-dim batch_matmul&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    XB, M, XK = x.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    YB, N, YK = y.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert XB == YB or XB == 1 or YB == 1, &quot;batch dimension doesn&#x27;t match&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert XK == YK, &quot;shapes of x and y is inconsistent&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nB = tvm.te.max(XB, YB)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nK = ((XK + 3) // 4) * 4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    reduce_k = te.reduce_axis((0, nK), name=&quot;k&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # pad for _dp4a vectorize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pad_x = te.compute(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (XB, M, nK),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lambda b, i, j: tvm.te.if_then_else(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            j &gt;= XK, tvm.runtime.convert(0).astype(x.dtype), x[b, i, j]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pad_y = te.compute(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (YB, N, nK),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lambda b, i, j: tvm.te.if_then_else(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            j &gt;= YK, tvm.runtime.convert(0).astype(y.dtype), y[b, i, j]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    out = te.compute(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (nB, M, N),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lambda b, i, j: te.sum(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pad_x[b if XB != 1 else 0, i, reduce_k].astype(out_dtype)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            * pad_y[b if YB != 1 else 0, j, reduce_k].astype(out_dtype),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            axis=[reduce_k],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        tag=&quot;batch_matmul_int8&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.add_flop(XB * M * N * nK * 2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return out</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@autotvm.register_topi_schedule(&quot;batch_matmul_int8.cuda&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def schedule_batch_matmul_int8(cfg, outs):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Batch Matmul schedule for int8 on CUDA&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outs = [outs] if isinstance(outs, te.tensor.Tensor) else outs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s = te.create_schedule([x.op for x in outs])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def _callback(op):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if &quot;batch_matmul_int8&quot; in op.tag:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            _schedule_batch_matmul_int8(cfg, s, op.output(0))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    traverse_inline(s, outs[0].op, _callback)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">_dp4a = dp4a(&quot;shared&quot;, &quot;shared&quot;, &quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def _schedule_batch_matmul_int8(cfg, s, output):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_x, input_y = s[output].op.input_tensors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    B, M, K = get_const_tuple(input_x.shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    _, N, _ = get_const_tuple(input_y.shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    k_factor = 4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert K % k_factor == 0, &quot;Input dimension must divide {}&quot;.format(k_factor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if K % 16 == 0:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        k_factor = 16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.define_split(&quot;tile_f&quot;, B, num_outputs=4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.define_split(&quot;tile_m&quot;, M, num_outputs=4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.define_split(&quot;tile_n&quot;, N, num_outputs=4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.define_split(&quot;tile_k&quot;, K // k_factor, num_outputs=2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cfg.define_knob(&quot;auto_unroll_max_step&quot;, [0, 256, 512, 1024])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    batch_matmul_op = s.outputs[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[input_x].compute_inline()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[input_y].compute_inline()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x_cache = s.cache_read(input_x, &quot;shared&quot;, [batch_matmul_op])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    y_cache = s.cache_read(input_y, &quot;shared&quot;, [batch_matmul_op])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    batch_matmul_cache = s.cache_write(batch_matmul_op.output(0), &quot;local&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # tile reduce axis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ko = batch_matmul_cache.op.reduce_axis[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ko, ki = s[batch_matmul_cache].split(ko, factor=4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ko, kt = cfg[&quot;tile_k&quot;].apply(s, batch_matmul_cache, ko)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # dp4a tensorize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_cache].tensorize(ki, _dp4a)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # tile axis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    f, m, n = batch_matmul_op.axis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    kernel_scope, f = s[batch_matmul_op].split(f, nparts=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bf, vf, tf, fi = cfg[&quot;tile_f&quot;].apply(s, batch_matmul_op, f)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bm, vm, tm, mi = cfg[&quot;tile_m&quot;].apply(s, batch_matmul_op, m)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bn, vn, tn, ni = cfg[&quot;tile_n&quot;].apply(s, batch_matmul_op, n)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].reorder(bf, bm, bn, vf, vm, vn, tf, tm, tn, fi, mi, ni)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # bind axis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(bf, tvm.te.thread_axis(&quot;blockIdx.z&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(bm, tvm.te.thread_axis(&quot;blockIdx.y&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(bn, tvm.te.thread_axis(&quot;blockIdx.x&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(vf, tvm.te.thread_axis(&quot;vthread&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(vm, tvm.te.thread_axis(&quot;vthread&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(vn, tvm.te.thread_axis(&quot;vthread&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(tf, tvm.te.thread_axis(&quot;threadIdx.z&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(tm, tvm.te.thread_axis(&quot;threadIdx.y&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].bind(tn, tvm.te.thread_axis(&quot;threadIdx.x&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # cache compute at</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_cache].compute_at(s[batch_matmul_op], tn)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    fo, mo, no = batch_matmul_cache.op.axis[:3]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_cache].reorder(ko, kt, fo, mo, no, ki)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # for load in [splited_x_op, splited_y_op]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for load in [x_cache, y_cache]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        s[load].compute_at(s[batch_matmul_cache], ko)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        outer, inner = s[load].split(s[load].op.axis[-1], factor=k_factor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        s[load].vectorize(inner)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused = s[load].op.axis[:-1] + [outer]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused = s[load].fuse(*fused)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused, tx = s[load].split(fused, factor=cfg[&quot;tile_n&quot;].size[2])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused, ty = s[load].split(fused, factor=cfg[&quot;tile_m&quot;].size[2])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused, tz = s[load].split(fused, factor=cfg[&quot;tile_f&quot;].size[2])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        s[load].bind(tz, tvm.te.thread_axis(&quot;threadIdx.z&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        s[load].bind(ty, tvm.te.thread_axis(&quot;threadIdx.y&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        s[load].bind(tx, tvm.te.thread_axis(&quot;threadIdx.x&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # max unroll</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].pragma(kernel_scope, &quot;auto_unroll_max_step&quot;, cfg[&quot;auto_unroll_max_step&quot;].val)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    s[batch_matmul_op].pragma(kernel_scope, &quot;unroll_explicit&quot;, False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h1>STEP 5：relay op strategy</h1>
<ul>
<li>relay 通过 strategy 类为每个算子选择合适的 compute 和 schedule</li>
<li>相关文件：python/tvm/relay/op/strategy/cuda.py</li>
<li>我们在这里增加对 batch_matmul_int8 算子计算和调度的选择策略：</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@batch_matmul_strategy.register([&quot;cuda&quot;, &quot;gpu&quot;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def batch_matmul_strategy_cuda(attrs, inputs, out_type, target):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;batch_matmul cuda strategy&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    strategy = _op.OpStrategy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x, y = inputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if x.dtype == &quot;int8&quot; and y.dtype == &quot;int8&quot; and out_type.dtype == &quot;int32&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        strategy.add_implementation(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            wrap_compute_batch_matmul(topi.cuda.batch_matmul_int8, need_out_dtype=True),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            wrap_topi_schedule(topi.cuda.schedule_batch_matmul_int8),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            name=&quot;batch_matmul_int8.cuda&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            plevel=10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        strategy.add_implementation(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            wrap_compute_batch_matmul(topi.cuda.batch_matmul),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            wrap_topi_schedule(topi.cuda.schedule_batch_matmul),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            name=&quot;batch_matmul.cuda&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            plevel=10,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>同时，由于我们实现的 batch_matmul_int8 的计算需要 out_dtype 作为参数，因此也需要同  时更改 python/tvm/relay/op/strategy/generic.py 文件中的 wrap_compute_batch_matmul 函数，增加一个 need_out_dtype 的参数：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># batch_matmul</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def wrap_compute_batch_matmul(topi_compute, need_auto_scheduler_layout=False, need_out_dtype=False):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;wrap batch_matmul topi compute&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def _compute_batch_matmul(attrs, inputs, out_type):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        args = [inputs[0], inputs[1], out_type.shape]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if need_auto_scheduler_layout:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            args.append(get_auto_scheduler_rewritten_layout(attrs))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if need_out_dtype:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            args.append(out_type.dtype)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return [topi_compute(*args)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return _compute_batch_matmul</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">machine learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/interview">interview</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/edit/main/website/docs/ml/optimization/speed_vit_in_tvm.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-06-23T14:03:16.000Z">Jun 23, 2024</time></b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/ml/optimization/script_calc_flops"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">计算模型需要的算力</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/ml/optimization/transformer"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">自动驾驶中基于Transformer的模型和硬件加速分析</div></a></nav></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>