"use strict";(self.webpackChunkblog_sample=self.webpackChunkblog_sample||[]).push([[1390],{3905:(e,n,t)=>{t.d(n,{Zo:()=>s,kt:()=>d});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function c(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?c(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):c(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},c=Object.keys(e);for(a=0;a<c.length;a++)t=c[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(a=0;a<c.length;a++)t=c[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var o=a.createContext({}),p=function(e){var n=a.useContext(o),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},s=function(e){var n=p(e.components);return a.createElement(o.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},k=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,c=e.originalType,o=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),u=p(t),k=r,d=u["".concat(o,".").concat(k)]||u[k]||m[k]||c;return t?a.createElement(d,i(i({ref:n},s),{},{components:t})):a.createElement(d,i({ref:n},s))}));function d(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var c=t.length,i=new Array(c);i[0]=k;var l={};for(var o in n)hasOwnProperty.call(n,o)&&(l[o]=n[o]);l.originalType=e,l[u]="string"==typeof e?e:r,i[1]=l;for(var p=2;p<c;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}k.displayName="MDXCreateElement"},4892:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>m,frontMatter:()=>c,metadata:()=>l,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const c={title:"element \u64cd\u4f5c",tags:["work"],editor:"caroot"},i=void 0,l={unversionedId:"cuda/element",id:"cuda/element",title:"element \u64cd\u4f5c",description:"\u8bbe\u7f6e\u5408\u7406\u7684 BlockSize \u548c GridSize",source:"@site/docs/cuda/element.md",sourceDirName:"cuda",slug:"/cuda/element",permalink:"/docs/cuda/element",draft:!1,editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/cuda/element.md",tags:[{label:"work",permalink:"/docs/tags/work"}],version:"current",lastUpdatedAt:1697382725,formattedLastUpdatedAt:"Oct 15, 2023",frontMatter:{title:"element \u64cd\u4f5c",tags:["work"],editor:"caroot"},sidebar:"tutorialSidebar",previous:{title:"GPU",permalink:"/docs/cuda/other"},next:{title:"\u8bbe\u7f6ecuda kernel\u4e2d\u7684grid_size\u548cblock_size",permalink:"/docs/cuda/grid_size\u548cblock_size"}},o={},p=[{value:"\u8bbe\u7f6e\u5408\u7406\u7684 BlockSize \u548c GridSize",id:"\u8bbe\u7f6e\u5408\u7406\u7684-blocksize-\u548c-gridsize",level:3},{value:"\u4f7f\u7528\u5411\u91cf\u5316\u64cd\u4f5c",id:"\u4f7f\u7528\u5411\u91cf\u5316\u64cd\u4f5c",level:3},{value:"\u8c03\u7528\u94fe",id:"\u8c03\u7528\u94fe",level:3}],s={toc:p},u="wrapper";function m(e){let{components:n,...t}=e;return(0,r.kt)(u,(0,a.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cuda"},"// Write ReLU Functor. \ntemplate<typename T>\nstruct ReluFunctor {\n  OF_DEVICE_FUNC T operator()(T x) const {\n    const T zero_val = static_cast<T>(0); \n    return (x > zero_val) ? x : zero_val; \n  }\n};\n\n// Use CUDA Elementwise Template. \nOF_CUDA_CHECK((cuda::elementwise::Unary(ReluFunctor<T>(), elem_cnt, dx->mut_dptr<T>(),\n                                        x->dptr<T>(), ctx->stream()->As<ep::CudaStream>()->cuda_stream())));\n")),(0,r.kt)("h3",{id:"\u8bbe\u7f6e\u5408\u7406\u7684-blocksize-\u548c-gridsize"},"\u8bbe\u7f6e\u5408\u7406\u7684 BlockSize \u548c GridSize"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"- \u8bbe\u7f6eCUDA Kernel\u4e2d\u7684grid_size\u548cblock_size\n- \u4e3b\u6d41\u67b6\u6784\u91cc\uff0c\u6bcf\u4e2a Block \u6700\u5927\u5bc4\u5b58\u5668\u6570\u91cf\u662f 64 K  \n- \u6bcf\u4e2a\u7ebf\u7a0b\u6240\u80fd\u4f7f\u7528\u7684\u6700\u5927\u5bc4\u5b58\u5668\u6570\u91cf\u662f 255 \u4e2a  \n- \u5728\u4f7f\u7528\u6700\u5927\u5bc4\u5b58\u5668\u6570\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u90a3\u6bcf\u4e2a Block \u6700\u591a\u80fd\u542f\u52a8\xa0 `64 * 1024 / 255 = 256` \xa0\u4e2a\u7ebf\u7a0b\uff08\u5f802\u7684\u500d\u6570\u53d6\u6574\uff09,\u56e0\u6b64\u8fd9\u91cc\u6211\u4eec\u8bbe\u5b9a\u4e86\u4e00\u4e2a\u5e38\u91cf\xa0 `constexpr int kBlockSize = 256;` \u3002  \n- \u800c Grid Size \u5927\u5c0f\u7684\u8bbe\u7f6e\u89c4\u5219\u5728\xa0 `GetNumBlocks` \xa0\u8fd9\u4e2a\u51fd\u6570\u4e2d\uff1a  \n    -  \n      ``` cuda\n                  constexpr int kBlockSize = 256\n                  constexpr int kNumWaves = 32;\n                  \n                  inline cudaError_t GetNumBlocks(int64_t n, int* num_blocks) {\n                    ...\n                    /*\n                    n: The number of the elements. \n                    sm_count: The number of the SM. \n                    tpm: The maximum resident threads in per multiprocessor. \n                    */\n                    *num_blocks = std::max<int>(1, std::min<int64_t>((n + kBlockSize - 1) / kBlockSize,\n                                                                     sm_count * tpm / kBlockSize * kNumWaves));\n                    return cudaSuccess;\n                  }\n      ```\n- \u7ebf\u7a0b\u5757\u6700\u5c0f\u4e2a\u6570\u4e3a1  \n- \u7ebf\u7a0b\u5757\u6700\u5927\u4e2a\u6570\u662f\u4ece\xa0 `\u5904\u7406\u6240\u6709\u5143\u7d20\u6240\u9700\u6700\u5c0f\u7684\u7ebf\u7a0b\u603b\u6570` \xa0\u548c\xa0 `wave \u6570\u76ee*GPU \u4e00\u6b21\u53ef\u4ee5\u8c03\u5ea6 SM \u6570\u91cf * \u6bcf\u4e2a SM \u6700\u5927 block \u6570` \xa0\u4e2d\u53d6\u6700\u5c0f\u503c\uff0c\u8fd9\u91cc\u6211\u4eec\u7684 wave \u6570\u76ee\u8bbe\u7f6e\u4e3a\u56fa\u5b9a32\u5927\u5c0f  \n")),(0,r.kt)("h3",{id:"\u4f7f\u7528\u5411\u91cf\u5316\u64cd\u4f5c"},"\u4f7f\u7528\u5411\u91cf\u5316\u64cd\u4f5c"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'- \u5927\u90e8\u5206 Elementwise \u7b97\u5b50\u7684\u8ba1\u7b97\u903b\u8f91\u8f83\u4e3a\u7b80\u5355\uff0c\u74f6\u9888\u4e3b\u8981\u662f\u5728\u5e26\u5bbd\u5229\u7528\u4e0a\u3002  \n- \u800c CUDA \u91cc\u4e5f\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u6570\u636e\u7c7b\u578b\u6765\u652f\u6301\u5411\u91cf\u5316\u64cd\u4f5c\uff0c\u5982 `float2` \uff0c `float4` \uff0c\u5c31\u662f\u5c062\u4e2a\u62164\u4e2a float \u6570\u636e\u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u3002\u5728\u4e00\u4e9b\u9ad8\u6027\u80fd\u8bad\u7ec3\u63a8\u7406\u5e93\u5982\xa0 `LightSeq` \xa0\u5c31\u4f7f\u7528\u4e86\u5927\u91cf\u7684\xa0 `float4` \xa0\u7c7b\u578b\uff1a  \n  ``` cuda\n          template <typename T>\n          __global__ void ker_layer_norm(T *ln_res, T *vars, T *means, const T *inp,\n                                         const T *scale, const T *bias, int hidden_size) {\n            // step 0. compute local sum\n            float l_sum = 0;\n            float l_square_sum = 0;\n            const float4 *inp_f4 = (const float4 *)inp + blockIdx.x * hidden_size; // use float4\n            for (uint idx = threadIdx.x; idx < hidden_size; idx += blockDim.x) {\n              float4 val = inp_f4[idx];\n              ...\n            }\n          }\n  ```\n- \u5728\u5b9e\u9645\u4e2d\uff0c\u6211\u4eec\u7684\u7b97\u5b50\u9700\u8981\u652f\u6301\u4e0d\u540c\u6570\u636e\u7c7b\u578b(\u5982 int, half)\uff0c\u5982\u679c\u91c7\u7528 CUDA \u5185\u7f6e\u7684\u5411\u91cf\u5316\u6570\u636e\u7c7b\u578b\u64cd\u4f5c\uff0c\u663e\u7136\u8981\u7ed9\u6bcf\u4e2a\u7b97\u5b50\u5199\u591a\u4e2a\u7248\u672c\uff0c\u589e\u52a0\u4e86\u5f00\u53d1\u8d1f\u62c5\u3002\u4e3a\u6b64\u6211\u4eec\u5b9e\u73b0\u4e86\u4e00\u4e2a\xa0 `Pack` \xa0\u6570\u636e\u7ed3\u6784\uff0c\u7528\u4e8e\u7075\u6d3b\u652f\u6301\u4e0d\u540c\u6570\u636e\u7c7b\u578b\u7684\u5411\u91cf\u5316\u3002  \n- \u6211\u4eec\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\xa0 `PackType` \xa0\u7c7b\u578b\u7c7b\u578b\u6765\u4ee3\u8868\u5411\u91cf\u5316\u7684\u6570\u636e\uff0c\u5b83\u4ee3\u8868\u7684\uff08\u5411\u91cf\u5316\u540e\u7684\uff09\u6570\u636e\u5927\u5c0f\u4e3a\xa0 `sizeof(T) * pack_size` \u3002  \n-  \n  ``` cuda\n          template<typename T, int pack_size>\n          struct GetPackType {\n            using type = typename std::aligned_storage<pack_size * sizeof(T), pack_size * sizeof(T)>::type;\n          };\n          \n          template<typename T, int pack_size>\n          using PackType = typename GetPackType<T, pack_size>::type;\n  ```\n- \u7136\u540e\u5b9e\u73b0\u4e86\u4e00\u4e2a\xa0 `union` \xa0\u7c7b\u578b\xa0 `Pack` \uff0c\u5b83\u5185\u90e8\u5b9a\u4e49\u4e86\xa0 `PackType<T, pack_size> storage;` \xa0\u6765\u5360\u7528\u7a7a\u95f4\uff1a  \n-  \n  ``` cuda\n          template<typename T, int pack_size>\n          union Pack {\n            static_assert(sizeof(PackType<T, pack_size>) == sizeof(T) * pack_size, "");\n            __device__ Pack() {\n              // do nothing\n            }\n            PackType<T, pack_size> storage;\n            T elem[pack_size];\n          };\n  ```\n- \u4e0e\xa0 `storage` \xa0\u5171\u4eab\u5185\u5b58\u7684\uff0c\u8fd8\u6709\xa0 `T elem[pack_size];` \xa0\u3002**\u8fd9\u6837\u65b9\u4fbf\u540e\u7eed\u7684 Elementwise \u64cd\u4f5c\uff1a\u5728\u540e\u7eed\u8ba1\u7b97\u91cc\uff0c\u6211\u4eec\u5bf9**\xa0**elem**\xa0**\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5e94\u7528 `functor` \uff0c\u5f97\u5230\u8f93\u51fa\u7ed3\u679c\u3002**  \n- CUDA \u91cc\u6700\u5927\u652f\u6301128 bit \u7684 pack \u5927\u5c0f\uff0c\u800c\u5728\u6d6e\u70b9\u6570\u636e\u7c7b\u578b\u4e2d\uff0c\u6700\u5c0f\u7684\u7c7b\u578b\uff08half\uff09\u5927\u5c0f\u4e3a16 bit\uff0c\u6700\u591a\u80fd\u628a128 / 16=8 \u4e2a half \u6570\u636e pack \u5230\u4e00\u8d77\uff0c\u56e0\u6b64\u6211\u4eec\u8bbe\u7f6e\u4e86\u8fd9\u4e24\u4e2a\u5e38\u91cf\uff0c `kMaxPackBytes` \xa0\u8868\u793a pack \u6700\u5927\u5b57\u8282\u6570\uff0c `kMaxPackSize` \xa0\u8868\u793a pack \u6570\u636e\u7684\u6700\u5927\u4e2a\u6570  \n')),(0,r.kt)("h3",{id:"\u8c03\u7528\u94fe"},"\u8c03\u7528\u94fe"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"- \u8ddf\u8e2a\xa0 `oneflow/core/cuda/elementwise.cuh` \xa0\u4e2d\u7684\u5b9e\u73b0\uff0c\u4f1a\u53d1\u73b0\uff0c\u8fd9\u5957\u6a21\u677f\u4f1a\u5206\u522b\u4e3a\u4e00\u5143\u3001\u4e8c\u5143\u3001\u4e09\u5143\u7684 Elementwise \u63d0\u4f9b\u63a5\u53e3\uff1a `Unary` \u3001 `Binary` \u3001 `Ternary` \uff0c\u6587\u7ae0\u5f00\u59cb\u5904\u7684\xa0 `ReLU` \xa0\u7b97\u5b50\u5c31\u4f7f\u7528\u4e86\xa0 `Unary` \xa0\u7684\u63a5\u53e3\u3002  \n- \u8fdb\u4e00\u6b65\u5206\u6790\u53ef\u4ee5\u53d1\u73b0\uff0c\u5b83\u4eec\u7ecf\u8fc7\u5c42\u5c42\u8c03\u7528\u540e\uff0c\u5176\u5b9e\u6700\u7ec8\u90fd\u4f1a\u8c03\u7528\u5230\xa0 `ApplyGeneric` \uff0c\u57fa\u672c\u8c03\u7528\u5173\u7cfb\u5982\u4e0b\uff1a  \n    \n  Unary/Binary/Ternary -> xxxFactory -> GenericLauncher<...>::Launch -> ApplyGeneric(CUDA Kernel)  \n    \n  `ApplyGeneric` \xa0\u8fd9\u4e2a CUDA Kernel \u4e2d\u6240\u505a\u7684\u4e3b\u8981\u5de5\u4f5c\u662f\uff1a  \n    - \u6839\u636e\u53c2\u6570\u521b\u5efa\u4e00\u4e2a\xa0 `functor`  \n    - \u8fdb\u5165\u5faa\u73af\uff0c\u9488\u5bf9\u6253\u5305\uff08pack\uff09\u540e\u7684\u6570\u636e\uff0c\u8c03\u7528\xa0 `ApplyPack` \xa0\u51fd\u6570\uff0c\u6bcf\u8c03\u7528\u4e00\u6b21\xa0 `ApplyPack` \uff0c\u5c31\u5904\u7406\u4e00\u6279 pack \u540e\u7684\u6570\u636e  \n    - \u5f53\u6700\u540e\u5b58\u5728\u5143\u7d20\u4e2a\u6570\u4e0d\u80fd\u88ab\xa0 `pack_size` \xa0\u6574\u9664\u7684\u60c5\u51b5\u65f6\uff0c\u9700\u8981\u8ba9\u7ebf\u7a0b\u5904\u7406\u4e0b\u5c3e\u90e8\u5269\u4f59\u5143\u7d20  \n-  \n  ``` cuda\n          template<int pack_size, bool tail, typename FactoryT, typename R, typename... IN>\n          __global__ void __launch_bounds__(kBlockSize)\n              ApplyGeneric(FactoryT factory, int64_t n_pack, PackType<R, pack_size>* pack_r,\n                           const PackType<IN, pack_size>*... pack_in, int64_t n_tail, R* tail_r,\n                           const IN*... tail_in) {\n            auto functor = factory();\n            const int global_tid = blockIdx.x * kBlockSize + threadIdx.x;\n            for (int64_t i = global_tid; i < n_pack; i += blockDim.x * gridDim.x) {\n              pack_r[i] = ApplyPack<pack_size, decltype(functor), R, IN...>(\n                  functor, (FetchPack<IN, pack_size>(pack_in + i).elem)...);\n            }\n            if (tail && global_tid < n_tail) { tail_r[global_tid] = functor((tail_in[global_tid])...); }\n          }\n  ```\n- `ApplyPack` \u51fd\u6570\u5b9a\u4e49\u5982\u4e0b\uff0c\u5b83\u5bf9\u4e00\u4e2a\xa0 `pack` \xa0\u5185\u7684\u5143\u7d20\u505a\u4e86\u4e2a\u5faa\u73af\uff0c\u5bf9\xa0 `elem` \xa0\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u8c03\u7528\xa0 `functor` \xa0\uff0c\u5f97\u5230\u8f93\u51fa\u7ed3\u679c\u5e76\u8fd4\u56de\uff1a  \n-  \n  ``` cuda\n          template<int pack_size, typename FunctorT, typename R, typename... IN>\n          __device__\n              typename std::enable_if<HasApply2<FunctorT>::value == false, PackType<R, pack_size>>::type\n              ApplyPack(const FunctorT& functor, const IN... in[pack_size]) {\n            Pack<R, pack_size> ret;\n          #pragma unroll\n            for (int j = 0; j < pack_size; ++j) { ret.elem[j] = functor((in[j])...); }\n            return ret.storage;\n          }\n  ```\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h3",{parentName:"li",id:"\u9488\u5bf9-half2-\u6570\u636e\u7c7b\u578b\u4f18\u5316"},"\u9488\u5bf9 half2 \u6570\u636e\u7c7b\u578b\u4f18\u5316"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"CUDA \u5b98\u65b9\u6709\u9488\u5bf9 half2 \u63a8\u51fa\u4e00\u7cfb\u5217\u7279\u6b8a\u6307\u4ee4\uff0c\u5982\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"hadd2")," \xa0\u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e24\u4e2a\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"half2")," \xa0\u6570\u636e\u7684\u52a0\u6cd5\uff0c\u8fdb\u800c\u63d0\u9ad8\u541e\u5410\u91cf\u3002  "),(0,r.kt)("li",{parentName:"ul"},"\u8003\u8651\u5230\u8fd9\u79cd\u60c5\u51b5\uff0cOneFlow \u7ed9\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"ApplyPack")," \xa0\u51fd\u6570\u7279\u5316\u4e86\u4e00\u4e2a\u7248\u672c\uff0c\u901a\u8fc7\u8c03\u7528 functor \u7684\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"apply2")," \xa0\u51fd\u6570\uff0c\u6765\u8c03\u7528 half2 \u76f8\u5173\u7279\u6b8a\u6307\u4ee4\uff0c\u63a5\u53e3\u5982\u4e0b  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-cuda"},"          template<int pack_size, typename FunctorT, typename R, typename... IN>\n          __device__ typename std::enable_if<HasApply2<FunctorT>::value == true && pack_size % 2 == 0,\n                                             PackType<R, pack_size>>::type\n          ApplyPack(const FunctorT& functor, const IN... in[pack_size]) {\n            Pack<R, pack_size> ret;\n          #pragma unroll\n            for (int j = 0; j < pack_size; j += 2) { functor.Apply2(ret.elem + j, (in + j)...); }\n            return ret.storage;\n          }\n"))),(0,r.kt)("li",{parentName:"ul"},"\u4ee5\u5148\u524d\u7684\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"Cast")," \xa0\u7b97\u5b50\u4e3a\u4f8b\uff0c\u6211\u4eec\u5728\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"CastFunctor")," \xa0\u5185\u90e8\u901a\u8fc7\u8c03\u7528\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"__float22half2_rn")," \xa0\u6307\u4ee4\uff0c\u5c06\u4e00\u4e2a float2 \u6570\u636e\u8f6c\u6362\u4e3a\u4e00\u4e2a half2 \u6570\u636e\u3002  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-cuda"},"          template<typename From>\n          struct CastFunctor<half, From, typename std::enable_if<!std::is_same<From, half>::value>::type> {\n            ...\n          \n            __device__ void Apply2(half* to, const From* from) const {\n              float2 f2;\n              f2.x = static_cast<float>(from[0]);\n              f2.y = static_cast<float>(from[1]);\n              *reinterpret_cast<half2*>(to) = __float22half2_rn(f2);\n            }\n          };\n"))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("h3",{parentName:"li",id:"\u6269\u5c55\u591a\u5143\u64cd\u4f5c"},"\u6269\u5c55\u591a\u5143\u64cd\u4f5c"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"\u5c06 Elementwise \u7b97\u5b50\u8fdb\u4e00\u6b65\u5206\u4e3a\u4e00\u5143\u3001\u4e8c\u5143\u3001\u4e09\u5143\u64cd\u4f5c\u3002\u5e76\u5229\u7528\u5de5\u5382\u6a21\u5f0f\uff0c\u4f7f\u5f97\u4ed6\u4eec\u6700\u7ec8\u7edf\u4e00\u8c03\u7528\xa0 ",(0,r.kt)("inlineCode",{parentName:"li"},"ApplyGeneric")," \u3002\u8fd9\u79cd\u8bbe\u8ba1\u65b9\u5f0f\u6613\u4e8e\u62d3\u5c55\uff1a\u5f53\u9700\u8981\u652f\u6301\u66f4\u591a\u8f93\u5165\u7684\u64cd\u4f5c\u65f6\uff0c\u53ea\u9700\u8981\u7f16\u5199\u5bf9\u5e94\u7684\u5de5\u5382\u5373\u53ef\u3002  "),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-cuda"},"          template<typename FunctorT>\n          struct SimpleFactory {\n            explicit SimpleFactory(FunctorT functor) : tpl(functor) {}\n            __device__ FunctorT operator()() const { return tpl; }\n          \n           private:\n            FunctorT tpl;\n          };\n          \n          template<typename FactoryT, typename R, typename A>\n          inline cudaError_t UnaryWithFactory(FactoryT factory, int64_t n, R* r, const A* a,\n                                              cudaStream_t stream) {\n            return GenericLauncher<FactoryT, R, A>::Launch(factory, n, r, a, stream);\n          }\n          \n          template<typename FunctorT, typename R, typename A>\n          inline cudaError_t Unary(FunctorT functor, int64_t n, R* r, const A* a, cudaStream_t stream) {\n            return UnaryWithFactory(SimpleFactory<FunctorT>(functor), n, r, a, stream);\n          }\n          \n          // BinaryWithFactory TernaryWithFactory ... \n          // Binary Ternary ... \n")))))))}m.isMDXComponent=!0}}]);